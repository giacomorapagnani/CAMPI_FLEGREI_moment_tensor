{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 16:17:02.443 Python[4454:76992] +[IMKClient subclass]: chose IMKClient_Legacy\n",
      "2024-11-08 16:17:02.443 Python[4454:76992] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from pyrocko.gf import LocalEngine, Target, DCSource, ws\n",
    "from pyrocko import trace\n",
    "from pyrocko.gui.marker import PhaseMarker\n",
    "\n",
    "# The store we are going extract data from:\n",
    "store_id = 'campiflegrei_near'\n",
    "\n",
    "# First, download a Greens Functions store. If you already have one that you\n",
    "# would like to use, you can skip this step and point the *store_superdirs* in\n",
    "# the next step to that directory.\n",
    "\n",
    "\n",
    "# We need a pyrocko.gf.Engine object which provides us with the traces\n",
    "# extracted from the store. In this case we are going to use a local\n",
    "# engine since we are going to query a local store.\n",
    "engine = LocalEngine(store_superdirs=['/Users/giaco/UNI/PhD_CODE/GIT/CAMPI_FLEGREI_moment_tensor/GF_STORES'])\n",
    "\n",
    "# Define a list of pyrocko.gf.Target objects, representing the recording\n",
    "# devices. In this case one station with a three component sensor will\n",
    "# serve fine for demonstation.\n",
    "#IV.CPOZ.      40.821072      14.11911        52.0        0.00\n",
    "#IV.CAAM.      40.820065      14.142049       170.0       0.00\n",
    "#IV.CBAC.      40.810901      14.08057        77.0        0.00\n",
    "\n",
    "channel_codes = 'NEZ'\n",
    "targets = [\n",
    "    Target(\n",
    "        lat=40.820065,\n",
    "        lon=14.142049,\n",
    "        store_id=store_id,\n",
    "        codes=('', 'CAAM', 'NF', channel_code))\n",
    "    for channel_code in channel_codes]\n",
    "\n",
    "\n",
    "# Let's use a double couple source representation.\n",
    "source_dc = DCSource(\n",
    "    lat=40.805833,\n",
    "    lon=14.108,\n",
    "    depth=3900,\n",
    "    strike=306.,\n",
    "    dip=49.,\n",
    "    rake=-69.,\n",
    "    magnitude=3.)\n",
    "\n",
    "# Processing that data will return a pyrocko.gf.Reponse object.\n",
    "response = engine.process(source_dc, targets)\n",
    "\n",
    "# This will return a list of the requested traces:\n",
    "synthetic_traces_nf = response.pyrocko_traces()\n",
    "\n",
    "\n",
    "channel_codes = 'NEZ'\n",
    "targets = [\n",
    "    Target(\n",
    "        lat=40.820065,\n",
    "        lon=14.142049,\n",
    "        store_id=store_id,\n",
    "        codes=('', 'CAAM', 'TH', channel_code))\n",
    "    for channel_code in channel_codes]\n",
    "\n",
    "# Let's use a double couple source representation.\n",
    "source_dc = DCSource(\n",
    "    lat=40.805833,\n",
    "    lon=14.108,\n",
    "    depth=1300,\n",
    "    strike=295.,\n",
    "    dip=56.,\n",
    "    rake=57.,\n",
    "    magnitude=3.)\n",
    "\n",
    "# Processing that data will return a pyrocko.gf.Reponse object.\n",
    "response = engine.process(source_dc, targets)\n",
    "\n",
    "# This will return a list of the requested traces:\n",
    "synthetic_traces_th = response.pyrocko_traces()\n",
    "\n",
    "synthetic_traces = []\n",
    "for tr in synthetic_traces_nf:\n",
    "    tr.differentiate(n=1, order=4, inplace=True)\n",
    "    synthetic_traces.append(tr)\n",
    "for tr in synthetic_traces_th:\n",
    "    tr.differentiate(n=1, order=4, inplace=True)\n",
    "    synthetic_traces.append(tr)\n",
    "# In addition to that it is also possible to extract interpolated travel times\n",
    "# of phases which have been defined in the store's config file.\n",
    "store = engine.get_store(store_id)\n",
    "\n",
    "#markers = []\n",
    "#for t in targets:\n",
    "#    dist = t.distance_to(source_dc)\n",
    "#    depth = source_dc.depth\n",
    "#    arrival_time = store.t('begin', (depth, dist))\n",
    "#    m = PhaseMarker(tmin=arrival_time,\n",
    "#                    tmax=arrival_time,\n",
    "#                    phasename='P',\n",
    "#                    nslc_ids=(t.codes,))\n",
    "#    markers.append(m)\n",
    "\n",
    "# Finally, let's scrutinize these traces.\n",
    "trace.snuffle(synthetic_traces)#, markers=markers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
